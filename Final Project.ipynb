{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930f82c8",
   "metadata": {},
   "source": [
    "# Final Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d766ee",
   "metadata": {},
   "source": [
    "# Correlation Between Companies in The Same Industry\n",
    "\n",
    "Summary of Contents\n",
    "\n",
    "- [1 Introduction](#toc_1)\n",
    "- [2 Questions 2 heading](#toc_2)\n",
    "- [3 Import Required Libraries](#toc_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149bde3",
   "metadata": {},
   "source": [
    "<a name=\"toc_1\"></a>\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185240c",
   "metadata": {},
   "source": [
    "intro intro intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606424ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca111b28",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2a7bd",
   "metadata": {},
   "source": [
    "This project uses the following data sets the information contained within are publicly available:\n",
    "\n",
    "1. sp500_info.csv: \n",
    "    * S&P 500 component stocks including their symbol and sector name, and sub sector name <br>\n",
    "    (Wikipedia 2023, https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)  \n",
    "    \n",
    "2. asx_15_info.csv: \n",
    "    * Top 20 Shares by Value for the ASX <br>\n",
    "    (ASX 2023, https://www.asx.com.au/data/dw_sharesbyvalue.pdf)  \n",
    "      \n",
    "3. prices_shares.csv: <br>\n",
    "    * 12 Months Historical Data for 100 S&P500 shares and 15 ASX shares (in their local currency): <br>\n",
    "    (Aroussi, 2023; Yahoo Finance, 2023)  \n",
    "        \n",
    "4. prices_fx.csv: \n",
    "    * 12 Months Historical Data for a basket of currencies: <br>\n",
    "    (Aroussi, 2023; Yahoo Finance, 2023)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92063281",
   "metadata": {},
   "source": [
    "# Style Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe65f6",
   "metadata": {},
   "source": [
    "<p style=\"background-color:Yellow;\">test</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37429ba4",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#B8E2F2;\">\n",
    "    <b>Finding:</b> test test test \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908aaf9",
   "metadata": {},
   "source": [
    "<a name=\"toc_2\"></a>\n",
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9c004",
   "metadata": {},
   "source": [
    "What is the break down by industry of the sample set of companies taken from the S&P500.\n",
    "\n",
    "Given a sample of 115 diferent stocks:\n",
    "* How many different pairs are possible to analyze\n",
    "* How many different pairs within the same industry are possible to analyze and compare to the 'total' universe of stocks\n",
    " \n",
    "What is the overall correlation profile of the pairs within the sample?  \n",
    "\n",
    "Are pairs in the same industry more closely correlated in their price movements than random pairs?\n",
    "\n",
    "Do pairs in some industries show better correlation than others?\n",
    "\n",
    "If there is a difference in correlation across industries, are there any apparent reasons for this or additional steps that could be taken to try and determine those?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c2bd5",
   "metadata": {},
   "source": [
    "<a name=\"toc_3\"></a>\n",
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cb2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d053b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcb72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e3bfda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d21196",
   "metadata": {},
   "source": [
    "# Set Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ac8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Input Files\n",
    "STOCK_PRICES_FNAME = \"prices_shares.csv\"\n",
    "FX_PRICES_FNAME = \"prices_fx.csv\"\n",
    "SP500_MEMBERS_FNAME = \"sp500_info.csv\"\n",
    "ASX_MEMBERS_FNAME = \"asx_15_info.csv\"\n",
    "\n",
    "#FILEPATH = \"C:\\\\Dropbox\\\\Variance\\\\UNSW\\\\ZZEN9021\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72200a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cols = ['Symbol', 'Security','GICS Sector']\n",
    "\n",
    "data = [\n",
    "['BHP.AX', 'BHP GROUP' ,'Materials'],\n",
    "['FMG.AX', 'FORTESCUE', 'Materials'],\n",
    "['MQG.AX', 'MACQUARIE GROUP', 'Financials'],\n",
    "['CBA.AX', 'COMMONWEATH BANK', 'Financials'],\n",
    "['RIO.AX', 'RIO TINTO', 'Materials'],\n",
    "['CSL.AX', 'CSL', 'Health Care'],\n",
    "['WDS.AX', 'WOODSIDE','Energy'],\n",
    "['ANZ.AX', 'ANZ GROUP', 'Financials'],\n",
    "['PLS.AX', 'PILBARAMIN', 'Materials'],\n",
    "['NAB.AX', 'NATIONAL AUSTRALIA BANK', 'Financials'],\n",
    "['WBC.AX', 'WESTPAC ', 'Financials'],\n",
    "['RMD.AX', 'RESMED', 'Health Care'],\n",
    "['NCM.AX', 'NEWCREST', 'Materials'],\n",
    "['NST.AX', 'NTH STAR', 'Materials'],\n",
    "['GMG.AX', 'GOODMAN GROUP', 'Real Estate'],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data = data, columns=cols)\n",
    "\n",
    "df.to_csv('asx_15_info.csv', index=False)\n",
    "df\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tickers/symbols of currencies that we wish to handle\n",
    "FX_TICKERS = [\"AUDUSD=X\", \"HKDUSD=X\", \"JPYUSD=X\", \"SGDUSD=X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183d69c",
   "metadata": {},
   "source": [
    "The key data we are accessing is pricing information for stocks and fx rates.\n",
    "\n",
    "Periodically we need to refresh this information as components of the indexes change, corporate actions occur etc.\n",
    "\n",
    "However, obtaining this information requires downloading it and thus we want to limit that to when required and not download it every time we run the program.\n",
    "\n",
    "We thus set a flag (REFRESH_DATA) which we can adjust before running the program identifying  whether to refresh our data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e81318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running within Ed this needs to remain as False as their are restrictions on accessing external web sites\n",
    "REFRESH_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621dde5",
   "metadata": {},
   "source": [
    "Set constants to determine limits on file size and number of pairs processed to limit processing and memory requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c963e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of choosing all 500 names from the S&P500, pick a selection to reduce the file sizes\n",
    "SP500_SAMPLE_SIZE = 100\n",
    "\n",
    "# From our list of all generated pairs, select a random sample to reduce processing requiremens\n",
    "#RDM_SAMPLE_SIZE = 20000\n",
    "RDM_SAMPLE_SIZE = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b0c185",
   "metadata": {},
   "source": [
    "# Obtain Names in SP500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e93ef2",
   "metadata": {},
   "source": [
    "If the refresh data flag is set to True, we run the function to scrape the list of names in the S&P500 from Wikipedia and save this to a csv file.\n",
    "\n",
    "If flag is set to false, the program will use the current version of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f17342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_sp500_info():\n",
    "    \"\"\"\n",
    "    Function to Scrape Details About S&P500 Components from Wikipedia.\n",
    "    Saves the current S&P Components into a csv file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scrape the list of components companies in the S&P500 as per Wikipedia\n",
    "    table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    \n",
    "    # Take the first item in the list obtained from table which contains a dataframe of current S&P components \n",
    "    df = table[0]\n",
    "      \n",
    "    # Save the component stocks to a csv file\n",
    "    df.to_csv(SP500_MEMBERS_FNAME, index=False)\n",
    "    \n",
    "# If refresh flag is True, download current data via running the obtain_sp_500_info function\n",
    "if REFRESH_DATA:\n",
    "    obtain_sp500_info()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e6d97",
   "metadata": {},
   "source": [
    "Read the Most current version of the csv file that contains the S&P component information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc59efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_info_df = pd.read_csv(SP500_MEMBERS_FNAME)\n",
    "sp500_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the number of S&P500 members we are going to review given processing constraints\n",
    "\n",
    "sp500_info_df = sp500_info_df[:SP500_SAMPLE_SIZE].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047e40d",
   "metadata": {},
   "source": [
    "Review the number of members to check that it equals the input constant SP500_SAMPLE_SIZE and also that there are no duplicate symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SP500_SAMPLE_SIZE)\n",
    "print(sp500_info_df['Symbol'].count())\n",
    "print(len(sp500_info_df['Symbol'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc67d4c",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">&#x2705;</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d5daf",
   "metadata": {},
   "source": [
    "Check for any periods in the stock names for US listed stocks (which includes all our S&P500 members).  Yahoo Finance, which is where we download the prices from, uses the convention that A shares and B shares utilize dashes in their names instead of periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95180de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_info_df[sp500_info_df['Symbol'].str.contains(\".\", regex=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c27668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to replace periods with dashs within the Symbol columns for S&P500 related names as per Yahoo Finance convention\n",
    "sp500_info_df['Symbol'] = sp500_info_df['Symbol'].str.replace(\".\", \"-\", regex=False)\n",
    "\n",
    "# Check to ensure this was successful\n",
    "sp500_info_df[sp500_info_df['Symbol'].str.contains(\".\", regex=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ad570",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">&#x2705;</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6833e3",
   "metadata": {},
   "source": [
    "# Obtain Names in ASX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11afe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "asx_info_df = pd.read_csv(ASX_MEMBERS_FNAME)\n",
    "asx_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4283b7",
   "metadata": {},
   "source": [
    "# Merge ASX and S&P500 Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_info_df = pd.concat([asx_info_df, sp500_info_df[['Symbol', 'Security', 'GICS Sector']]])\n",
    "all_stocks_info_df                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_info_df['GICS Sector'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0e2f8",
   "metadata": {},
   "source": [
    "# Obtain Prices From CSV or Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ef1c0",
   "metadata": {},
   "source": [
    "If we have chosen to refresh the data, we will now download the latest prices from Yahoo Finance using the yfinance Library.\n",
    "\n",
    "We will download prices for both our stocks and also for the Foreign Exchange (FX) rates.\n",
    "\n",
    "We will then update the pricing related csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f981648",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DATA:\n",
    "    \n",
    "    # Download stock data and FX data from yfinance\n",
    "    stock_prices_df = yf.download(list(all_stocks_info_df['Symbol']), start=\"2022-01-01\", end=\"2022-12-31\")[\"Adj Close\"]\n",
    "    raw_fx_prices_df = yf.download(FX_TICKERS, start=\"2022-01-01\", end=\"2022-12-31\")[\"Adj Close\"]\n",
    "    \n",
    "    # Write new prices to csv\n",
    "    stock_prices_df.to_csv(STOCK_PRICES_FNAME)\n",
    "    raw_fx_prices_df.to_csv(FX_PRICES_FNAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab7972",
   "metadata": {},
   "source": [
    "Whether we have just refreshed the prices or not, we will read the share and FX prices from their csv files.  If refreshed, they will contain the data just downloaded.  If not, the prior version of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd462a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Daily Prices for the Stocks and FX Rates from their respective csv files\n",
    "stock_prices_df = pd.read_csv(STOCK_PRICES_FNAME)\n",
    "raw_fx_prices_df = pd.read_csv(FX_PRICES_FNAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8afa5f",
   "metadata": {},
   "source": [
    "## Review the Raw FX Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca79a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fx_prices_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda10a7",
   "metadata": {},
   "source": [
    "It quite difficult to analyze the JPY and HKD columns given they are inverted vs how they are conventionally displayed.\n",
    "\n",
    "Inverting them for reasonableness analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_summ = raw_fx_prices_df.describe()\n",
    "# Invert FX Rate for display purposes for JPY and HKD to what is conventionally displayed\n",
    "fx_summ.loc[['mean', 'min', 'max'],['JPYUSD=X', 'HKDUSD=X']] \\\n",
    "            = 1 / fx_summ.loc[['mean', 'min', 'max'],['JPYUSD=X', 'HKDUSD=X']]\n",
    "fx_summ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3466a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Min and max ranges as well as distributions seem in line with the known characteristics of the currencies\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f0acd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "We do not have the same number of records for each currency\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9beda",
   "metadata": {},
   "source": [
    "<p style=\"background-color:Yellow;\">test</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e545450",
   "metadata": {},
   "source": [
    "&#10060;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a44b1",
   "metadata": {},
   "source": [
    "To fix this we will resample the data using the ffil() function.\n",
    "First though we'll create a copy of the data to avoid changing original data removing need to reload if rerunning workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    " fx_prices = raw_fx_prices_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9740dd",
   "metadata": {},
   "source": [
    "Prior to doing the resampling and for later analysis it is better if we convert dates from being string values a column,  to Datetime values and also set them as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the Date and set as the Index\n",
    "fx_prices['Date'] = pd.to_datetime(fx_prices['Date'], format = \"%Y-%m-%d\")\n",
    "fx_prices = fx_prices.set_index('Date', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data to fill any missing values\n",
    "# This will also give a price for the week-ends, but that will get dropped later when we merge with the share prices df\n",
    "fx_prices = fx_prices.resample('D').last().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e152c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the column counts to ensure they are now consistent\n",
    "fx_prices.describe().loc['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333af8b1",
   "metadata": {},
   "source": [
    "&#x2705;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ed620",
   "metadata": {},
   "source": [
    "Here is how our FX data now looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce0bff",
   "metadata": {},
   "source": [
    "&#x2705;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccf238",
   "metadata": {},
   "source": [
    "## Review the Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f538e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2447cde",
   "metadata": {},
   "source": [
    "**Lets Review the price values for reasonableness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff705cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimium Share Price Value Across All Stocks: ${stock_prices_df.select_dtypes(include='number').min().min():,.02f}\")\n",
    "print(f\"Maximum Share Price Value Across All Stocks: ${stock_prices_df.select_dtypes(include='number').max().max():,.02f}\")\n",
    "print(f\"Mean Share Price Value Across All Stocks: ${stock_prices_df.select_dtypes(include='number').mean().mean():,.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7634f294",
   "metadata": {},
   "source": [
    "The range of values for individual shares prices is quite large and thus direct comparision of absolute values would required scaling of the prices.\n",
    "However, the range seems reasonable given the dataset - there are no negative values and no extremely large or small values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb1088",
   "metadata": {},
   "source": [
    "&#x2705;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b5a77",
   "metadata": {},
   "source": [
    "Lets create a scatter plot to visualize the price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_prices_by_stock = stock_prices_df.select_dtypes(include='number').mean()\n",
    "av_prices_by_stock.index = pd.Series(range(len(av_prices_by_stock)))\n",
    "plt.scatter(x = av_prices_by_stock.values,\n",
    "            y = av_prices_by_stock.index,\n",
    "           )\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Company Number')\n",
    "plt.title('Mean Price for Each Company')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce68e5d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Not Great:</b> That does not look so great with a small number of obvious outliers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2919f6",
   "metadata": {},
   "source": [
    "Lets check to see if these represent errors or just outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest two price values by stock\n",
    "stock_prices_df.select_dtypes(include='number').max().sort_values()[-2:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc2b26",
   "metadata": {},
   "source": [
    "Checking these manually to price sources **, the prices look accurate.  Thus the values represent outliers rather than errors.\n",
    "\n",
    "While there are several ways to handle these outliers depending the analysis being performed and the reason for the outliers, for our analysis we are going to retain them in our data set.\n",
    "\n",
    "** \n",
    "https://finance.yahoo.com/quote/NVR?p=NVR&.tsrc=fin-srch\n",
    "https://finance.yahoo.com/quote/BKNG?p=BKNG&.tsrc=fin-srch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef27eb9",
   "metadata": {},
   "source": [
    "**Examing the Number of Records for Each Stock**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_prices_df.describe().loc['count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab25f2a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The maximum number of rows is 252, and this is the case for >75% of the rows.  As a reasonableness check, there are 260 (52 * 5) week days in the year and some of these will be public holidays.  So we expect somewhere around 250 trading days in a year given stock markets are not open on week-ends and we have to then deduct for public holidays - so 252 looks reasonable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339acc5",
   "metadata": {},
   "source": [
    "# Format Share Pricing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e66a6",
   "metadata": {},
   "source": [
    "## Convert Share Prices to USD Equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we convert the dates to datetime format and set them as the index\n",
    "\n",
    "stock_prices_df['Date'] = pd.to_datetime(stock_prices_df['Date'], format = \"%Y-%m-%d\")\n",
    "stock_prices_df = stock_prices_df.set_index('Date', drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2513a33",
   "metadata": {},
   "source": [
    "Now we add a column for the FX rate applicable given the ticker code format:\n",
    "* Australian stocks have .AX in their ticker, \n",
    "* Japanese stocks have .T, \n",
    "* Hong Kong stocks .HK, \n",
    "* Singapore stocks .SI; and\n",
    "* US stocks have no period in their ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44200690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add currency column based on ticker code format\n",
    "for ticker in stock_prices_df.columns:\n",
    "    if \".AX\" in ticker:\n",
    "        stock_prices_df[ticker] = stock_prices_df[ticker] * fx_prices[\"AUDUSD=X\"]\n",
    "    elif \".HK\" in ticker:\n",
    "        stock_prices_df[ticker] = stock_prices_df[ticker] * fx_prices[\"HKDUSD=X\"]\n",
    "    elif \".T\" in ticker:\n",
    "        stock_prices_df[ticker] = stock_prices_df[ticker] * fx_prices[\"JPYUSD=X\"]\n",
    "    elif \".SI\" in ticker:\n",
    "        stock_prices_df[ticker] = stock_prices_df[ticker] * fx_prices[\"SGDUSD=X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ead97",
   "metadata": {},
   "source": [
    "## Eliminate shares with less than 245 trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7323fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Names Which Should be Eliminated\n",
    "low_counts = stock_prices_df.count()[stock_prices_df.count()<250]\n",
    "print(low_counts)\n",
    "\n",
    "low_counts = list(low_counts.index)\n",
    "print(low_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate Names with a Low Number of Trading Days Present\n",
    "stock_prices_df = stock_prices_df.drop(columns=low_counts).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check removal was successful\n",
    "stock_prices_df.count().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06a21c",
   "metadata": {},
   "source": [
    "&#x2705;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7470a",
   "metadata": {},
   "source": [
    "## Fill Prices for Names Missing only a Small Number of Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill any missing stock prices\n",
    "stock_prices_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Backward fill any remaining missing stock prices\n",
    "stock_prices_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "stock_prices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5c4db",
   "metadata": {},
   "source": [
    "# Create a Universe of Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b271b0",
   "metadata": {},
   "source": [
    "Now that we have imported and cleansed the data, we need to start manipulating it to get the answers required.\n",
    "\n",
    "Key to this is breaking the price data for all the companies into pairs that can be analyzed.  For Example, Microsoft (MSFT) vs Google (GOOGL).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17263e6b",
   "metadata": {},
   "source": [
    "Using all the names we have data for, we can create a list of all possible pair combinations using the itertools library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_pairs = [list(pair) for pair in itertools.combinations(stock_prices_df.columns, 2)]\n",
    "\n",
    "print(f\"The Number of All Possible Unique Pairs is: {len(all_possible_pairs):,.0f}\")\n",
    "print(f\"\\nSome Examples: {all_possible_pairs[:5]} \\n{all_possible_pairs[-5:]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31774d18",
   "metadata": {},
   "source": [
    "We may want to instead look at a sample of names, instead of the full universe.  This may be because we have processing constrainsts etc.  However, we want a random sample rather than just picking the first 100 names in case their is some bias in the way they are ordered.\n",
    "\n",
    "We have set the sample size via the input constant (RDM_SAMPLE_SIZE) in the Set Inputs section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample of pairs randomly from the our universe of all possible pairs\n",
    "random_pairs = sample(all_possible_pairs, RDM_SAMPLE_SIZE)\n",
    "print(random_pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d4170",
   "metadata": {},
   "source": [
    "## Add Industry to Pairs List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bcf54",
   "metadata": {},
   "source": [
    "The key factor we are seeking to test is Industry.  That is, if in names in the same industry show better correlation or related statistics vs random pairs. \n",
    "\n",
    "To do this we are going to have to merge information from multiple inputs:\n",
    "- the ticker names for the pairs will come from the list of pairs we generated;\n",
    "- the Industry name will come from the all_stocks_info_df\n",
    "- Same Industry Column will be a engineered column we create\n",
    "\n",
    "The Same Industry column will make queries and analysis on the dataset simplier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31265a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame which lists all possible pairs, the industry of each name in the pair and if they are the same.\n",
    "\n",
    "# Start with the all the pair combinations\n",
    "all_possible_pairs_df = pd.DataFrame(all_possible_pairs, columns=['Ticker1', 'Ticker2'])\n",
    "\n",
    "# write to csv to check file size\n",
    "all_possible_pairs_df.to_csv(\"all_possible_pairs_df.csv\")\n",
    "\n",
    "# Add the Industry Name for the first ticker\n",
    "all_possible_pairs_df = pd.merge(all_possible_pairs_df, all_stocks_info_df[['Symbol', 'GICS Sector']], how='inner', left_on = 'Ticker1', right_on = 'Symbol')\n",
    "# Add the Industry name for the second ticker\n",
    "all_possible_pairs_df = pd.merge(all_possible_pairs_df, all_stocks_info_df[['Symbol', 'GICS Sector']], how='inner', left_on = 'Ticker2', right_on = 'Symbol')\n",
    "\n",
    "# Remove excess columns and tidy up column names\n",
    "all_possible_pairs_df.drop(columns = ['Symbol_x', 'Symbol_y'], inplace=True)\n",
    "all_possible_pairs_df.rename(columns={\"GICS Sector_x\": \"Ind1\", \"GICS Sector_y\": \"Ind2\"}, inplace=True)\n",
    "\n",
    "# Create a new column 'Same Industry' which identifies if all the two names in the pair are from the same industry\n",
    "all_possible_pairs_df['Same Industry'] = np.where(all_possible_pairs_df['Ind1'] == all_possible_pairs_df['Ind2'], 'Yes', 'No')\n",
    "all_possible_pairs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29828fcc",
   "metadata": {},
   "source": [
    "Construct a DataFrame for the Random Pairs sample in the same format as that for all the possible pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the base df from the list of list of random pairs\n",
    "random_pairs_df = pd.DataFrame(random_pairs, columns=['Ticker1', 'Ticker2'])\n",
    "\n",
    "# Add the extra columns required via merging with the df containing all the pairs\n",
    "random_pairs_df = pd.merge(random_pairs_df, all_possible_pairs_df, how='inner',\n",
    "                          left_on= ['Ticker1', 'Ticker2'],\n",
    "                          right_on= ['Ticker1', 'Ticker2'])\n",
    "\n",
    "random_pairs_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb924ae5",
   "metadata": {},
   "source": [
    "### Analysis of Names by Sector ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e0334",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_info_df['GICS Sector'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Minimum Number of Members within a Sector Group is: {all_stocks_info_df.groupby('GICS Sector').size().min()}\")\n",
    "print(f\"The Median Number of Members within a Sector Group is: {all_stocks_info_df.groupby('GICS Sector').size().median()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_info_df.groupby('GICS Sector').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c4993",
   "metadata": {},
   "source": [
    "### Build and Display Graphs Analysing the Distribution of the Sector Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51010275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Counts of The Number of Names Within Each Sector\n",
    "sector_counts = all_stocks_info_df.groupby('GICS Sector')['Symbol'].count().sort_values(axis=0)\n",
    "\n",
    "# Bucket The Industries into Those That Have a High Number of Members and \"Others\"\n",
    "sector_counts_series = sector_counts[-8:]\n",
    "sector_counts_series['Other'] = sector_counts_series[:-8].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ad633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seaborn color palette for our graphs\n",
    "colors = sns.color_palette(\"Blues\", len(sector_counts_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create a Series of Graphs to Show the Distribution and Makeup of the Sector Membership\n",
    "def display_sector_graphs(colors, sector_counts, sector_counts_series):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 25))\n",
    "    fig.suptitle('Sector Category Splits', y = 0.95, fontweight='bold')\n",
    "\n",
    "    \"\"\"\n",
    "    # Display Histogram Showing What Are the Most Common Number of Members Within a Sector Group\n",
    "    ax = fig.add_subplot(4, 1, 1)\n",
    "    ax.hist(sub_industry_counts,\n",
    "            bins = len(np.arange(1,sub_industry_counts.max())+1),\n",
    "            )\n",
    "    ax.set_ylabel('Frequency of Occurence')\n",
    "    ax.set_xlabel('Number of Members Within Sub-Index')\n",
    "    ax.set_title('Breakout of the Number of Members Within Each Sector')\n",
    "    \"\"\"\n",
    "\n",
    "    # Display Pie Chart\n",
    "    ax = fig.add_subplot(3, 1, 1)\n",
    "    ax.pie(sector_counts_series,\n",
    "        labels = sector_counts_series.index,\n",
    "        colors = colors,\n",
    "            )\n",
    "    ax.set_title('Sector Split', fontweight='bold')\n",
    "\n",
    "    # Bar Chart of the Sub-Industries With the Most Members\n",
    "    ax = fig.add_subplot(3, 1, 2)\n",
    "    ax.barh(sector_counts_series[:-1].index , sector_counts_series[:-1].values)\n",
    "    ax.set_title('Top Sector Member Numbers', fontweight='bold')\n",
    "\n",
    "    # Display Box Plot\n",
    "    ax = fig.add_subplot(3, 1, 3)\n",
    "    ax.boxplot(all_stocks_info_df.groupby('GICS Sector')['Symbol'].count())\n",
    "    ax.set_title('Distribution of Number of Members Within Each Sector', fontweight='bold')\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa044edb",
   "metadata": {},
   "source": [
    "When we review the how many stocks/ companies fall into each Sector we see that most Sub-Industries only have a very small number of members.  However, there are also a small number of Sub-Industries that have 10 plus members.\n",
    "\n",
    "So the distribution is definitely quite skewed.\n",
    "\n",
    "The following graphs demonstrate that distribution and also highlights which Sector groups have the most number of members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125382e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = display_sector_graphs(colors, sector_counts, sector_counts_series)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f77d9",
   "metadata": {},
   "source": [
    "Where the Sector only has a single member, comparing members within the same industry will not be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18e21a",
   "metadata": {},
   "source": [
    "Given we are looking to compare companies within the same industry vs companies not in the same industry, we want to identify if any sectors have less than 2 names in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_info_df.groupby('GICS Sector')['Symbol'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0fa3a7",
   "metadata": {},
   "source": [
    "## Analyse Ratio of Same Industry Vs Different Industry Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33335aff",
   "metadata": {},
   "source": [
    "### Full Universe of Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs_all = len(all_possible_pairs_df.index)\n",
    "num_pairs_same_ind_all = len(all_possible_pairs_df[all_possible_pairs_df['Same Industry'] == 'Yes'].index)\n",
    "\n",
    "print(f\"Number of Pairs In Total: {num_pairs_all:,}\")\n",
    "print(f\"Number of Pairs in the Same Industry: {num_pairs_same_ind_all:,}\")\n",
    "print(f\"Percentage of pairs in the same industry: {num_pairs_same_ind_all/num_pairs_all * 100:,.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cea62",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54960dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs_all_samp = len(random_pairs_df.index)\n",
    "num_pairs_same_ind_samp = len(random_pairs_df[random_pairs_df['Same Industry'] == 'Yes'].index)\n",
    "\n",
    "print(f\"Number of Pairs In Total: {num_pairs_all_samp:,}\")\n",
    "print(f\"Number of Pairs in the Same Industry: {num_pairs_same_ind_samp:,}\")\n",
    "print(f\"Percentage of pairs in the same industry: {num_pairs_same_ind_samp/num_pairs_all_samp * 100:,.02f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = [[num_pairs_all, num_pairs_same_ind_all, num_pairs_same_ind_all/num_pairs_all * 100], \n",
    "                          [num_pairs_all_samp, num_pairs_same_ind_samp, num_pairs_same_ind_samp/num_pairs_all_samp * 100]], \n",
    "                  columns=['Number of Total Pairs', 'Number of Pairs in Same Industry', '% of Pairs in the Same Industry'])\n",
    "df.index = ['Entire Population', 'Sample']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7c7c4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Our sample does seem representative of the total population in term pairs in the same industry vs all pairs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e722b",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc31b4f",
   "metadata": {},
   "source": [
    "# Calculate The Correlation Between Various Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_array = []\n",
    "for i in range(len(random_pairs_df)):\n",
    "    \n",
    "    #ratio = stock_prices_df[pair[0]]/ stock_prices_df[pair[1]]\n",
    "    corr = stock_prices_df[random_pairs[i][0]].corr(stock_prices_df[random_pairs[i][1]])\n",
    "    \n",
    "    corr_array.append([random_pairs[i][0], random_pairs[i][1], corr])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "corr_df = pd.DataFrame(data=corr_array, columns=['Ticker1', 'Ticker2', 'Correlation'])\n",
    "corr_df = pd.merge(corr_df, random_pairs_df, how='inner',\n",
    "                  left_on = ['Ticker1', 'Ticker2'], right_on = ['Ticker1', 'Ticker2'])\n",
    "\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices_df.iloc[:,:5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddbd7e",
   "metadata": {},
   "source": [
    "## Analyze Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00caffcd",
   "metadata": {},
   "source": [
    "We are analyzing the absolute values of the correlations as we are interested in the magnitude of the corrleations - negative correlations are as usual as positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_all = abs(corr_df['Correlation']).describe()\n",
    "corr_same_ind = abs(corr_df[corr_df['Same Industry'] == 'Yes']['Correlation']).describe()\n",
    "\n",
    "df = pd.DataFrame(corr_all)\n",
    "df = pd.DataFrame({'Corr all': corr_all, 'Corr Same Industry': corr_same_ind})\n",
    "\n",
    "df.loc['Median', :] \\\n",
    "= [abs(corr_df['Correlation']).median(), abs(corr_df[corr_df['Same Industry'] == 'Yes']['Correlation']).median()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9c72d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Finding:</b> At a summary level there does appear to be a higher correlation level for pairs in the same industry</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69411f2d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#B8E2F2;\">\n",
    "    <b>Finding:</b> test test test \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ee619",
   "metadata": {},
   "source": [
    "## Analyse by Industry : Are Some Industry Groups Better Than Others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1393ab",
   "metadata": {},
   "source": [
    "Build a DataFrame which gives us some summary info by Industry for Pairs Which are Both in the Same Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the df of all correlations, extract same industry pairs and get the median correlation and count for those those pairs\n",
    "df = corr_df[corr_df['Same Industry'] == 'Yes'].groupby('Ind1').agg(Median =('Correlation', 'median'),\\\n",
    "                                                                   Count=('Correlation','count'))\n",
    "df = df.reset_index()\n",
    "df['Median'] = abs(df['Median'])\n",
    "df = df.sort_values(['Median', 'Count']).set_index('Ind1', drop=True)\n",
    "df.index.name = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cd761",
   "metadata": {},
   "source": [
    "If we only have one pair in an industry, it is difficult to make any comparision of that industry vs another.  Thus we will limit our comparison to industries with at least 8 names in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c00b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit our target dataframe to only include sectors with 10 or more members\n",
    "df = df.sort_values('Count')\n",
    "df = df[df['Count']>=10]\n",
    "\n",
    "df = df.sort_values('Median')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median correlations\n",
    "medians_same_ind = abs(df['Median'])\n",
    "medians_all_ind = abs(corr_df.groupby('Ind1')['Correlation'].median())\n",
    "\n",
    "# We only want to plot the industries that have sufficient same industry pairs\n",
    "medians_all_ind = medians_all_ind[medians_all_ind.index.isin(df.index)]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=[10,10])\n",
    "\n",
    "# Set a width for the bars\n",
    "bar_width = 0.3\n",
    "\n",
    "# We have to define bar positions if we want the different plots to be side by side\n",
    "bar1_positions = np.arange(len(medians_same_ind))\n",
    "bar2_positions = bar1_positions + bar_width # Puts the position beside the prior bar\n",
    "\n",
    "# Create our bar charts\n",
    "ax.barh(bar1_positions, medians_same_ind, height=bar_width, label='Median Correlation by Industry for Pairs in the Same Industry')\n",
    "ax.barh(bar2_positions, medians_all_ind, height=bar_width, label='Median Correlation by Industry for ALL Pairs')\n",
    "\n",
    "# Define y labels and title\n",
    "ax.set_yticks(bar1_positions + bar_width / 2)\n",
    "ax.set_yticklabels(medians_same_ind.index)\n",
    "ax.set_xlabel('Median Correlation')\n",
    "ax.set_ylabel('Industry')\n",
    "ax.set_title('Median Correlation by Industry')\n",
    "\n",
    "# Show legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d6656",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Finding:</b> The range of correlations does vary signficantly across industries\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3963554",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Finding:</b> This graph also reinforces the earlier finding that the correlation levels are higher for pairs which are both in the same industry vs disparate pairs - as the same industry pairs have higher correlation for almost all industries</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e6d06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Finding:</b> It appears that there seems to be INVERSE correlation between the number of members in the Sector and the Median correlation of Sector Members.\n",
    "    \n",
    "One possible explanation for this may be that Sectors with larger numbers of members may also be those defined broadly.  If the Sector is quite broad the business models within that sector are likley to become less closely related.\n",
    "\n",
    "This would require further data analysis and possibly include trying to create sub sectors to see if that creates higher correlation levels.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9336e7",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22973a5d",
   "metadata": {},
   "source": [
    "Each list item requires specific information. \n",
    "\n",
    "See https://www.student.unsw.edu.au/node/131 \n",
    "and https://www.student.unsw.edu.au/node/132.\n",
    "\n",
    "* List each item in alphabetical order, by author surname.\n",
    "* Titles should be in italics.\n",
    "* Each item should have a hanging indent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c9f69",
   "metadata": {},
   "source": [
    "Aroussi, R., 2023, yfinance.[python library]  \n",
    "> Available at https://pypi.org/project/yfinance/(Accessed: 3 August, 2023)\n",
    "\n",
    "ASX, 2023.  *Top 20 Shares by Value.* [pdf] \n",
    "> Available at https://www.asx.com.au/data/dw_sharesbyvalue.pdf (Accessed, August 3 2023).\n",
    "\n",
    "Wikipedia, 2023. *S&P 500 component stocks.*\n",
    "> Available at https://en.wikipedia.org/wiki/List_of_S%26P_500_companies (Accessed: July 31 2023)\n",
    "\n",
    "Yahoo Finance, 2023.  *Stock Market and Foreign Currency Historical Market Data.*  \n",
    "> Available at:\n",
    "    https://finance.yahoo.com/quote/[Symbol_Code]/history?p=[Symbol_Code](Accessed: 3 August, 2023)\n",
    "\n",
    "Yahoo Finance, 2023.  *Company Profile Data Incuding Sector Name.*  \n",
    "> Available at:\n",
    "    https://finance.yahoo.com/quote/[Symbol_Code]/profile?p=[Symbol_Code](Accessed: 3 August, 2023)\n",
    "\n",
    "> Note: 115 different stocks and four different foreign currencies were analyzed and thus the individual symbol codes for each are not listed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565453cd",
   "metadata": {},
   "source": [
    "# Discarded Graphs etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d9873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = stock_prices_df.iloc[:,:3].copy()\n",
    "\n",
    "pd.plotting.scatter_matrix(graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7eb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Pairplot on Correlations Might Show Something About Industries\n",
    "\n",
    "# Not really!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set()\n",
    "sns.pairplot(\n",
    "    #data = corr_df.head(),\n",
    "    data = corr_df,\n",
    "    hue = 'Ind1',\n",
    "    height = 5\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abf9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    #data = corr_df.head(),\n",
    "    data = corr_df,\n",
    "    hue = 'Same Industry',\n",
    "    height = 5\n",
    "    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c07391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe when notebook was last run all the way through successfully\n",
    "\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a25739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
